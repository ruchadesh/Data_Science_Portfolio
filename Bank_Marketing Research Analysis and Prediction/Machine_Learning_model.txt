1. Loading required Libraries and Dataset
In [1]:
# Load libraries
%matplotlib inline
import matplotlib.pyplot as plt
#setting dimension of graph
plt.rcParams["figure.figsize"]= (12, 7)

import pandas as pd
import numpy as np
import seaborn as sns

from pandas.tools.plotting import scatter_matrix

from sklearn.decomposition import PCA
from sklearn.preprocessing import scale
from sklearn.preprocessing import Imputer
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
In [2]:
# Load dataset
url = "C:/Users/rucha/Desktop/bank.csv"
dataset = pd.read_csv(url)

2. Data Exploration
In [3]:
#Information of data
dataset.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 45211 entries, 0 to 45210
Data columns (total 17 columns):
age           45211 non-null int64
job           45211 non-null object
marital       45211 non-null object
education     45211 non-null object
default       45211 non-null object
balance       45211 non-null int64
housing       45211 non-null object
loan          45211 non-null object
contact       45211 non-null object
day           45211 non-null int64
month         45211 non-null object
duration      45211 non-null int64
campaign      45211 non-null int64
pdays         45211 non-null int64
previous      45211 non-null int64
poutcome      45211 non-null object
is_success    45211 non-null object

dtypes: int64(7), object(10)
memory usage: 5.9+ MB
we have 45211 observations of 17 variables (7-Numerical Variables and 10-Categorical Variables).

In [4]:
#check for any missing values
dataset.apply(lambda x: sum(x.isnull()),axis=0)
Out[4]:
age           0
job           0
marital       0
education     0
default       0
balance       0
housing       0
loan          0
contact       0
day           0
month         0
duration      0
campaign      0
pdays         0
previous      0
poutcome      0
is_success    0
dtype: int64
Fortunatly there are no any explicit missing values for any variable.

In [5]:
# head
print(dataset.head())
   age           job  marital  education default  balance housing loan  
0   58    management  married   tertiary      no     2143     yes   no   
1   44    technician   single  secondary      no       29     yes   no   
2   33  entrepreneur  married  secondary      no        2     yes  yes   
3   47   blue-collar  married    unknown      no     1506     yes   no   
4   33       unknown   single    unknown      no        1      no   no   

   contact  day month  duration  campaign  pdays  previous poutcome is_success  
0  unknown    5   may       261         1     -1         0  unknown         no  
1  unknown    5   may       151         1     -1         0  unknown         no  
2  unknown    5   may        76         1     -1         0  unknown         no  
3  unknown    5   may        92         1     -1         0  unknown         no  
4  unknown    5   may       198         1     -1         0  unknown         no  
There are many 'unknown' values under Categorical variables.We have to treat them!!!

In [6]:
# Target variable distribution
count = dataset.groupby('is_success').size()
percent = count/len(dataset)*100
print(percent)
is_success
no     88.30152
yes    11.69848
dtype: float64
From the distribution of Target variable: "is_success" it is found that data is imbalanced becouse there is approx 88% is 'no' and 12% is 'yes'.



Analysis of Indepedent Numerical Variables

# Impute outliers function
def impute_outliers(df, column , minimum, maximum):
    col_values = df[column].values
    df[column] = np.where(np.logical_or(col_values<minimum, col_values>maximum), col_values.mean(), col_values)
    return df
In [8]:
#lets see statistic of Numerical variables before Outlier treatment
dataset.describe()


